{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron 2 Face Analyze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mait Application use detectron2 for face recognizer and image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Cuda that work or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "# imports are always needed\n",
    "import torch\n",
    "\n",
    "\n",
    "# get index of currently selected device\n",
    "torch.cuda.current_device() \n",
    "torch.cuda.device_count() \n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='my_dataset_val',\n",
       "          thing_classes=['acne',\n",
       "                         'blackhead',\n",
       "                         'nodule',\n",
       "                         'papule',\n",
       "                         'pustule',\n",
       "                         'whitehead'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def load_coco_json(json_file, image_root, dataset_name):\n",
    "    with open(json_file) as f:\n",
    "        coco = json.load(f)\n",
    "    \n",
    "    categories = {cat['id']: cat['name'] for cat in coco['categories']}\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    skipped_images = 0  # ตัวนับจำนวนภาพที่ถูกข้าม\n",
    "    skipped_annotations = 0  # ตัวนับจำนวน annotations ที่ถูกข้าม\n",
    "    \n",
    "    for img in coco['images']:\n",
    "        record = {}\n",
    "        \n",
    "        record[\"file_name\"] = os.path.join(image_root, img[\"file_name\"])\n",
    "        record[\"image_id\"] = img[\"id\"]\n",
    "        record[\"height\"] = img[\"height\"]\n",
    "        record[\"width\"] = img[\"width\"]\n",
    "        \n",
    "        annos = [anno for anno in coco['annotations'] if anno['image_id'] == img['id']]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            # ตรวจสอบว่า segmentation ไม่ว่างและไม่ใช่ 'iscrowd'\n",
    "            if not anno.get(\"segmentation\") or anno.get(\"iscrowd\"):\n",
    "                skipped_annotations += 1\n",
    "                continue  # ข้าม instance นี้\n",
    "                \n",
    "            # ตรวจสอบว่า segmentation เป็น list หรือ dict ตาม COCO format\n",
    "            segm = anno[\"segmentation\"]\n",
    "            if isinstance(segm, list):\n",
    "                # polygons\n",
    "                if len(segm) == 0:\n",
    "                    skipped_annotations += 1\n",
    "                    continue\n",
    "            elif isinstance(segm, dict):\n",
    "                # RLE\n",
    "                if not segm:\n",
    "                    skipped_annotations += 1\n",
    "                    continue\n",
    "            else:\n",
    "                skipped_annotations += 1\n",
    "                continue\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": anno[\"bbox\"],\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"category_id\": anno[\"category_id\"],\n",
    "                \"iscrowd\": anno[\"iscrowd\"]\n",
    "            }\n",
    "            obj[\"segmentation\"] = segm\n",
    "            objs.append(obj)\n",
    "        \n",
    "        if not objs:\n",
    "            skipped_images += 1  # เพิ่มตัวนับถ้าไม่มี annotations ที่ถูกต้อง\n",
    "            continue  # ข้าม image นี้ถ้าไม่มี annotations ที่ถูกต้อง\n",
    "                \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    print(f\"Loaded {len(dataset_dicts)} images from {dataset_name}, skipped {skipped_images} images with no valid annotations, skipped {skipped_annotations} annotations.\")\n",
    "    return dataset_dicts\n",
    "\n",
    "# ลงทะเบียน Dataset\n",
    "dataset_root = r\"C:\\Users\\nnewr\\Documents\\Mait_FaceAnalyze\\dataset\"\n",
    "\n",
    "train_json = os.path.join(dataset_root, \"train\", \"_annotations.coco.json\")\n",
    "train_images = os.path.join(dataset_root, \"train\")\n",
    "DatasetCatalog.register(\"my_dataset_train\", lambda: load_coco_json(train_json, train_images, \"my_dataset_train\"))\n",
    "MetadataCatalog.get(\"my_dataset_train\").set(thing_classes=[\"acne\", \"blackhead\", \"nodule\", \"papule\", \"pustule\", \"whitehead\"])\n",
    "\n",
    "valid_json = os.path.join(dataset_root, \"valid\", \"_annotations.coco.json\")\n",
    "valid_images = os.path.join(dataset_root, \"valid\")\n",
    "DatasetCatalog.register(\"my_dataset_val\", lambda: load_coco_json(valid_json, valid_images, \"my_dataset_val\"))\n",
    "MetadataCatalog.get(\"my_dataset_val\").set(thing_classes=[\"acne\", \"blackhead\", \"nodule\", \"papule\", \"pustule\", \"whitehead\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of import image with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 678 images from my_dataset_train, skipped 113 images with no valid annotations, skipped 114 annotations.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "# เลือกชุดข้อมูลที่จะตรวจสอบ เช่น ชุด Train\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):  # แสดง 3 ตัวอย่าง\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    if img is None:\n",
    "        print(f\"ไม่พบภาพ: {d['file_name']}\")\n",
    "        continue\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow(\"Sample\", out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'detectron2.data.transforms' has no attribute 'Compose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 54\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_transforms\u001b[39m():\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     48\u001b[0m         T\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)),\n\u001b[0;32m     49\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomFlip(prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, horizontal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, vertical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     50\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomBrightness(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m),\n\u001b[0;32m     51\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomContrast(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m),\n\u001b[0;32m     52\u001b[0m     ])\n\u001b[1;32m---> 54\u001b[0m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mAUGMENTATIONS \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# ตั้งค่า Anchor Sizes และ Aspect Ratios\u001b[39;00m\n\u001b[0;32m     57\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mANCHOR_GENERATOR\u001b[38;5;241m.\u001b[39mSIZES \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m, in \u001b[0;36mbuild_transforms\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_transforms\u001b[39m():\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m([\n\u001b[0;32m     48\u001b[0m         T\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)),\n\u001b[0;32m     49\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomFlip(prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, horizontal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, vertical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     50\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomBrightness(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m),\n\u001b[0;32m     51\u001b[0m         T\u001b[38;5;241m.\u001b[39mRandomContrast(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m),\n\u001b[0;32m     52\u001b[0m     ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'detectron2.data.transforms' has no attribute 'Compose'"
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import os\n",
    "from detectron2.data import transforms as T\n",
    "\n",
    "\n",
    "# สร้าง Configuration\n",
    "cfg = get_cfg()\n",
    "\n",
    "# โหลดการตั้งค่าจาก model zoo สำหรับ Mask R-CNN\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# ตั้งค่าชุดข้อมูล\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "# ตั้งค่า DataLoader\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "# ใช้น้ำหนักจาก pretrained model\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "# ตั้งค่า solver\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2000  # ปรับตามขนาด dataset ของคุณ\n",
    "\n",
    "# ตั้งค่า Learning Rate Scheduler\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 3\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.STEPS = (1500, 1800)  # ขั้นตอนที่ต้องลด Learning Rate\n",
    "\n",
    "# ตั้งค่า ROI Heads\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # จำนวนคลาสของคุณ\n",
    "\n",
    "# เปิดการใช้งาน Mask\n",
    "cfg.MODEL.MASK_ON = True\n",
    "\n",
    "# ตั้งค่า output directory\n",
    "cfg.OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ตั้งค่า Data Augmentation\n",
    "from detectron2.data import transforms as T\n",
    "\n",
    "def build_transforms():\n",
    "   return T.TransformList([\n",
    "        T.Resize((640, 640)),\n",
    "        T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        T.RandomBrightness(0.8, 1.2),\n",
    "        T.RandomContrast(0.8, 1.2),\n",
    "    ])\n",
    "\n",
    "cfg.INPUT.AUGMENTATIONS = build_transforms()\n",
    "\n",
    "# ตั้งค่า Anchor Sizes และ Aspect Ratios\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[32, 64, 128, 256, 512]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations missing segmentation: 31\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "valid_json_path = r\"C:\\Users\\nnewr\\Documents\\Mait_FaceAnalyze\\dataset\\valid\\_annotations.coco.json\"\n",
    "\n",
    "with open(valid_json_path, 'r') as f:\n",
    "    coco_val = json.load(f)\n",
    "\n",
    "# ตรวจสอบว่าทุก annotation มี segmentation ที่ไม่ว่างเปล่า\n",
    "missing_segmentation = [anno for anno in coco_val['annotations'] if not anno.get('segmentation') or anno.get('iscrowd')]\n",
    "\n",
    "print(f\"Number of annotations missing segmentation: {len(missing_segmentation)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import os\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "# ใช้ MyTrainer แทน DefaultTrainer\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# ประเมินผลหลังการฝึก\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
